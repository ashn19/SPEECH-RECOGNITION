## Hey, I'm [Ashith Nirmal P!](https://github.com/ashn19) ðŸ‘‹.



## SPEECH RECOGNITION
- Voice can combine what people say and how they say it by two-factor authentication in a single action. Other identifications like fingerprints, handwriting, iris, retina, face scans can also help in biometrics but voice identification is needed as an authentication that is both secure and unique. Voice can combine two factors, namely, personal voice recognition and telephone recognition. The goal of pattern recognition is to classify objects of interest into one of a number of categories or classes. The objects of interest are generically called patterns and in our case are sequences of acoustic vectors that are extracted from an input speech using the techniques described in the previous section. The classes here refer to individual speakers. Since the classification procedure in our case is applied on extracted features, it can be also referred to as feature matching.
These patterns comprise the training set and are used to derive a classification algorithm. The remaining patterns are then used to test the classification algorithm; these patterns are collectively referred to as the test set. If the correct classes of the individual patterns in the test set are also known, then one can evaluate the performance of the algorithm.
The state-of-the-art in feature matching techniques used in speaker recognition include Dynamic Time Warping (DTW), Hidden Markov Modeling (HMM), and Vector Quantization (VQ). In this project, the VQ approach will be used, due to ease of implementation and high accuracy. VQ is a process of mapping vectors from a large vector space to a finite number of regions in that space. Each region is called a cluster and can be represented by its center called a codeword. The collection of all codewords is called a codebook.

- 

### METHODOLOGY
-ï‚¡The core objective of this project is to identify the speaker with the given voice/speech input (unknown speaker) based on the trained voice model (known speakerâ€™s voice).
ï‚¡In this project we will experiment with the building and testing of an automatic speaker recognition system. In order to build such a system, one has to go through the following steps. We create two utility functions euc_dist and codebooks and two main functions: training and testing.
ï‚¡Our goal is to train a voice model (or more specific, a VQ codebook in the MFCC vector space) for each speaker S1 â€“ S8 using the corresponding sound file in the train folder. After this training step, the system would have knowledge of the voice characteristic of each (known) speaker. Next, in the testing phase, the system will be able to identify the (assumed unknown) speaker of each sound file in the test folder.
